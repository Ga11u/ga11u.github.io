<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Marc Page</title>
    <link>https://ga11u.github.io/</link>
      <atom:link href="https://ga11u.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Marc Page</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 31 Aug 2020 16:01:50 +0200</lastBuildDate>
    <image>
      <url>https://ga11u.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Marc Page</title>
      <link>https://ga11u.github.io/</link>
    </image>
    
    <item>
      <title>Using Nodetool in Cassandra for getting interesting Statistics</title>
      <link>https://ga11u.github.io/post/cassandra-using-nodetool-for-statistics/</link>
      <pubDate>Mon, 31 Aug 2020 16:01:50 +0200</pubDate>
      <guid>https://ga11u.github.io/post/cassandra-using-nodetool-for-statistics/</guid>
      <description>&lt;p&gt;Apache Cassadra is a well-known and powefurl distributed database which comes with its own tool for managing cassandra cluster and getting interesting information. In this post, I will show different &lt;code&gt;nodetool&lt;/code&gt; commands that I found really useful.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;nodetool&lt;/code&gt; command looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nodetool &amp;lt;options&amp;gt; &amp;lt;command&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where the basic option are the -h (&amp;ndash;host) to pass as argument the hostname or IP address of a cassandra node and the -p (&amp;ndash;port) to pass as a argument the port number where nodetool will make the connection (by default 7199). By can also use the -pwf (&amp;ndash;password-file) to pass the password file path or the -pw (&amp;ndash;password) to pass the	password string.&lt;/p&gt;
&lt;p&gt;Nodetool can be runned from either the same machine where Cassandra is installed and running or from an external machine using the apropiate options. In case we would like to use the nodetool in a running Cassandra docker service on a Swarm stack deployment it is enough to execture the nodetool command inside the running container:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -it &amp;lt;CONTAINER_ID&amp;gt; nodetool
#To find the CONTAINER_ID, it is possible to use `docker ps` on the node where Cassandra container is running
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;nodetool-status&#34;&gt;nodetool &lt;code&gt;status&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Nodetool status provides information about each node such as the status (up U or down D) and the state (normal N, leaving L, joining J, moving M), the node IP &lt;strong&gt;Address&lt;/strong&gt;, the amount of data used (&lt;strong&gt;Load&lt;/strong&gt;), the number of tokes, how much data is owned by the node (&lt;strong&gt;Owns&lt;/strong&gt;), the &lt;strong&gt;Host-ID&lt;/strong&gt; and the &lt;strong&gt;Rack&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack
UN  10.0.1.28  70.68 MiB  256          67.5%             da80b540-0424-4ad1-b64c-51cf4c46dcfe  rack1
UN  10.0.1.12  73.48 MiB  256          69.4%             fd8af11e-f1d9-4adb-abe5-84925113f9bb  rack1
UN  10.0.1.14  67.69 MiB  256          63.0%             e04c747d-ae77-476f-92fc-34bda99ab1e4  rack1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The status accept the argument &lt;code&gt;keyspace&lt;/code&gt; where we can pass the name of a keyspace to get information related to this specific keyspace, in case we have set more than one.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nodetool &amp;lt;options&amp;gt; status &amp;lt;keyspace&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;nodetool-tablestats&#34;&gt;nodetool &lt;code&gt;tablestats&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Nodetool tablestats provides information and statistics about keyspaces, index and tables. The information I found more interesting to check is the &lt;strong&gt;SSTable Compression Ratio&lt;/strong&gt; which represents the compression ratio (e.g., 0.25 means that 10MB of information are compressed to 2.5MB in Cassadra), the &lt;strong&gt;Read/Write count&lt;/strong&gt; and &lt;strong&gt;Local read/write count&lt;/strong&gt; which represent the total amount of read or write requests since the startup and the &lt;strong&gt;Read/Write latency&lt;/strong&gt; and &lt;strong&gt;Local read/write latency&lt;/strong&gt; the round trip time in milliseconds to comple the most recent read or write request.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;Keyspace : example-case
        Read Count: 1349
        Read Latency: 0.245 ms
        Write Count: 4032
        Write Latency: 0.10584201388888889 ms
        Pending Flushes: 0
                Table: corpus
                SSTable count: 1
                Space used (live): 74714036
                Space used (total): 74714036
                Space used by snapshots (total): 0
                Off heap memory used (total): 95800
                SSTable Compression Ratio: 0.25010121781248695
                Number of partitions (estimate): 42120
                Memtable cell count: 1344
                Memtable data size: 11265339
                Memtable off heap memory used: 0
                Memtable switch count: 0
                Local read count: 345
                Local read latency: 0.226478953 ms
                Local write count: 1344
                Local write latency: 0.1053876324 ms
... 
[output truncated]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With tablestats is possible to provide the argument &lt;code&gt;&amp;lt;keyspace.table&amp;gt;&lt;/code&gt; to visualise stats for a specific keyspace or table.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nodetool &amp;lt;options&amp;gt; tablestats &amp;lt;keyspace.table&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Deploying in Docker Swarm From Private a Repository</title>
      <link>https://ga11u.github.io/post/swarm-deploying-from-private-repo/</link>
      <pubDate>Mon, 31 Aug 2020 14:40:20 +0200</pubDate>
      <guid>https://ga11u.github.io/post/swarm-deploying-from-private-repo/</guid>
      <description>&lt;p&gt;By default Docker Swarm pull images from Docker Hub, but sometimes we want to have our own private repositories and private images. Then, a few things have to be changed to allow it.&lt;/p&gt;
&lt;p&gt;In this guide, I will show you how to do it, by using the example of GitLab repositories.&lt;/p&gt;
&lt;p&gt;Lets assume that we have our private images in GitLab and we have already deployed a swarm stack called &lt;code&gt;example-project&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The first thing you need to do is:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker login &amp;lt;gitlab-url&amp;gt;:&amp;lt;repository-port&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will need to check the port with your GitLab or repository provider, a common used port in GitLab is 4567.&lt;/p&gt;
&lt;p&gt;Then you will be asked to provide your &lt;code&gt;username&lt;/code&gt; and password. The &lt;code&gt;password&lt;/code&gt; is often a token or a secure key you have created only for accessing to your private repository.&lt;/p&gt;
&lt;p&gt;Finnaly, you can deploy your stack as always by adding the option &lt;code&gt;--with-registry-auth&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker stack deploy -c docker-compose.yml example-project --with-registry-auth
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Updating Doker Containers Without Downtime</title>
      <link>https://ga11u.github.io/post/updating-doker-containers-without-downtime/</link>
      <pubDate>Mon, 31 Aug 2020 12:26:20 +0200</pubDate>
      <guid>https://ga11u.github.io/post/updating-doker-containers-without-downtime/</guid>
      <description>&lt;p&gt;Updating a running container may be a critical task if not done properly, as it can cause undesired side effects or stop production processes. Thus, with this guide I want to show you how to conduct a conteiner update process in an easy and safe way.&lt;/p&gt;
&lt;p&gt;I assume you are using a container deployment and managment tool such as Swarm or Kubernates, otherwise I strongly recommend you to get familar with such kind of tools and use it on your applications. For the rest of this guide, I will use Swarm as a example.&lt;/p&gt;
&lt;p&gt;Lets imagine that we have the following service definition in a &lt;code&gt;docker-compose.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;services:
  cassandra1:
    &amp;lt;&amp;lt;: *cassandra-base
    environment:
      CASSANDRA_CLUSTER_NAME: cassandra-cluster
      CASSANDRA_PASSWORD: cassandra
      CASSANDRA_BROADCAST_ADDRESS: tasks.cassandra1
      CASSANDRA_LISTEN_ADDRESS: tasks.cassandra1
      CASSANDRA_SEEDS: &amp;quot;tasks.cassandra1,tasks.cassandra2,tasks.cassandra3&amp;quot; 
      CASSANDRA_PASSWORD_SEEDER: &amp;quot;yes&amp;quot;
    ports:
      - target: 7000
        published: 7000
      - target: 9042
        published: 9042
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This service creates an Apache Cassandra node which is connected in a cluster to other 2 nodes, making a cluster of 3 nodes. It also opens the ports 7000 and 9042.&lt;/p&gt;
&lt;p&gt;Now, we run &lt;code&gt;docker stack deploy -c docker-compose.yml example_project&lt;/code&gt; and our cluster of 3 nodes is succesfuly running and working. So far, so god!&lt;/p&gt;
&lt;p&gt;However, after a while we realise that we have forgoten to open the port 7199 from where we can connect with &lt;code&gt;nodetols&lt;/code&gt; tool to manage our cluster and get some statistics. &lt;em&gt;So what can we do now?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s easy, (1) update the &lt;code&gt;docker-compose.yml&lt;/code&gt; as we wish, e.g., with the port 7199:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;services:
  cassandra1:
    &amp;lt;&amp;lt;: *cassandra-base
    environment:
      CASSANDRA_CLUSTER_NAME: cassandra-cluster
      CASSANDRA_PASSWORD: cassandra
      CASSANDRA_BROADCAST_ADDRESS: tasks.cassandra1
      CASSANDRA_LISTEN_ADDRESS: tasks.cassandra1
      CASSANDRA_SEEDS: &amp;quot;tasks.cassandra1,tasks.cassandra2,tasks.cassandra3&amp;quot; 
      CASSANDRA_PASSWORD_SEEDER: &amp;quot;yes&amp;quot;
    ports:
      - target: 7000
        published: 7000
      - target: 9042
        published: 9042
      - target: 7199
        published: 7199
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(2) Run again the command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker stack deploy -c docker-compose.yml example_project
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In that way the Docker Swarm will create a new version of our service and stop old version after that.&lt;/p&gt;
&lt;p&gt;Finally, if everything has worked fine, we should be able to do something like this &lt;code&gt;nodetool tablestats -h &amp;lt;CASSANDRA_NODE_IP&amp;gt;&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Expanding Blazegraph Data Volume</title>
      <link>https://ga11u.github.io/post/expanding-blazegraph-data-volumes/</link>
      <pubDate>Thu, 27 Aug 2020 16:51:52 +0200</pubDate>
      <guid>https://ga11u.github.io/post/expanding-blazegraph-data-volumes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Expanding Cassandra Data Volumes</title>
      <link>https://ga11u.github.io/post/expanding-cassandra-data-volumes/</link>
      <pubDate>Thu, 27 Aug 2020 16:51:31 +0200</pubDate>
      <guid>https://ga11u.github.io/post/expanding-cassandra-data-volumes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scaling-out Blazegraph, is it possible?</title>
      <link>https://ga11u.github.io/post/blazegraph-scale-out/</link>
      <pubDate>Wed, 26 Aug 2020 10:26:28 +0200</pubDate>
      <guid>https://ga11u.github.io/post/blazegraph-scale-out/</guid>
      <description>&lt;p&gt;Blazegraph&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; is a high performance scale-out triple-store for big data which can support up to ~12.7B triples in a single machine (see previous 
&lt;a href=&#34;https://ga11u.github.io/post/triplestores-scale-out/&#34;&gt;post&lt;/a&gt;). Even though it is presented as an ultra high-performance graph database and designed to scale-out, the scale-out feature has not been that much supported as developers would wish.&lt;/p&gt;
&lt;p&gt;At the beginning (from the 2.0.0 release), the scale-out was moved to a Enterprise fueture under licence supriptions, as we can see from  the following information about High Availability (HA) and Scale-out features in the Blazegraph Blog (&lt;a href=&#34;https://blog.blazegraph.com/):&#34;&gt;https://blog.blazegraph.com/):&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Enterprise Features (HA and Scale-out)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Starting in release 2.0.0, the Scale-out and HA capabilities are moved to Enterprise features. These are available to uses with support and/or license subscription. If you are an existing GPLv2 user of these features, we have some easy ways to migrate. Contact us for more information. We’d like to make it as easy as possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Later, the support for High Availability was droped out from the project, due to the lack of open source community, as it is corroborated by Bryan Thompson (@thompsonbry), the Chief Scientist and founder of SYSTAP and one of the contributors of Blazegraph, in the issue #116 at Blazegraph/database GitHub (&lt;a href=&#34;https://github.com/blazegraph/database/issues/116):&#34;&gt;https://github.com/blazegraph/database/issues/116):&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The HA configuration is not functional in more recent releases. Systap halted development of the Blazegraph HA feature several years ago (long before we came to Amazon).  Full HA is a complex thing to develop and maintain with master failure, testing of the various failover configurations, longevity testing, targeted failure mode tests, etc.  We self-funded quite a bit, but we did not get the engagement from the open source community to make it worth while to continue HA as an open source feature.&lt;/p&gt;
&lt;p&gt;You can always do the poor man&amp;rsquo;s HA, put the updates onto a durable queue, and then apply writes to each server in parallel.  You would need to handle master failover of course.  Or you can capture the IChangeLog from one server and replicate the post-facto changes (in terms of statements added and removed) to the other servers, again using a durable queue to capture the post-commit change set.  To do the latter, you would also need to report additions to the dictionary indices (which is not currently done, but which would not be that difficult to add in the LexiconRelation and an apply loop interface for the replicas to apply the deltas on their local indices).  I think this might &amp;ldquo;just work&amp;rdquo;.  The local journal tracks the transactions in flight and manages the recycling of deleted records once no transaction can read on those records.  So transactional access to data should &amp;ldquo;work&amp;rdquo; on the replicas without doing anything else. Again, you would need to handle master failover, etc.&lt;/p&gt;
&lt;p&gt;Thanks, Bryan&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Currently, since Blazegraph was taken over by Amazon (Neptune AWS&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;), the project does not seem to be activly maintained. However, it is possible to scale-out Blazegraph and configure with HA clusters.&lt;/p&gt;
&lt;p&gt;The Blazegraph scale-out architecture (Figure 1) is based 
on a shared disk volume where all Blazegraph&amp;rsquo;s nodes have access to the data. This shared disck volume can be set-up accross different machines, racks or regions with servies like Gluster. A load balancer distributes the data requests and updates between the Blazegraph&amp;rsquo;s nodes and Zookeeper manages the services running on each node.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;scale-out-bg.svg&#34; alt=&#34;Blazegraph scale-out architecture&#34;&gt;















&lt;figure id=&#34;figure-blazegraph-scale-out-architecture&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;&#34; data-caption=&#34;Blazegraph scale-out architecture&#34;&gt;


  &lt;img src=&#34;&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Blazegraph scale-out architecture
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The Blazegraph scale-out architecture provides with horisontal scaling as both nodes an disks space can be extended. However, this architecture does not provide of distributed data along each node, as it would be the case of Apache Cassandra&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Due to the lack of documentation and support for clustered and HA Blazegraph deployment, the scale-out option is only for those fearless adventurers who wants to try out the clustered and HA version of Blazegraph. A guide about how to deploy the clustered configuration can be found at &lt;a href=&#34;https://github.com/blazegraph/database/wiki/ClusterGuide&#34;&gt;https://github.com/blazegraph/database/wiki/ClusterGuide&lt;/a&gt; with the following advice: &lt;code&gt;We recommend that you ask for help when attempting your first cluster install!&lt;/code&gt;, the HA configuration is explained at &lt;a href=&#34;https://github.com/blazegraph/database/wiki/HAJournalServer#Basic_Deployment,&#34;&gt;https://github.com/blazegraph/database/wiki/HAJournalServer#Basic_Deployment,&lt;/a&gt; and a example with the Wikidata deployment of Blazegraph (with 3 nodes) can be found at &lt;a href=&#34;https://wikitech.wikimedia.org/wiki/Nova_Resource:Wikidata-query/Documentation&#34;&gt;https://wikitech.wikimedia.org/wiki/Nova_Resource:Wikidata-query/Documentation&lt;/a&gt; (the author of this post doesn&amp;rsquo;t take responsabilities for your failed attempts or disasters &amp;ndash; if you success, I will like to hear and lear how you have manage it 😄).&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Still, the stand-alone version Blazegraph is a really interesting option for working with an open source triple-store which can manage big data volumes while providing high performance and support for RDF, SPARQL 1.1 and Gremlin.
  &lt;/div&gt;
&lt;/div&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://blazegraph.com&#34;&gt;https://blazegraph.com&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com/neptune&#34;&gt;https://aws.amazon.com/neptune&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://cassandra.apache.org&#34;&gt;https://cassandra.apache.org&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Is It Possible to Sale-out Open Source Triple-Stores?</title>
      <link>https://ga11u.github.io/post/triplestores-scale-out/</link>
      <pubDate>Fri, 21 Aug 2020 10:52:25 +0200</pubDate>
      <guid>https://ga11u.github.io/post/triplestores-scale-out/</guid>
      <description>&lt;p&gt;Semantic technologies are really interesting from a Big Data prespective. Yet, these technologies together with semantic web resources enhance Knowledge Graphs by providing reacher means for representing and defining facts, concepts, properties, relations and logic-rules, while facilitating knowledge graph understanding, integration and manipulation by using ontologies, standard vocabularies and linking its concepts to Linked Open Data (LOD) resources such as Wikidata, Schema.org or DBPedia. Nevertheless, Big Data cames with its known challanges like the need for systems that are able to scale-up and -out (vertical and horisontal scaling). Thus, semantic technologies and more precicely triple-stores which support RDF and SPARQL following the W3C and semantic web standards (i.e., the databases designed for storing knowledge graphs represented with triples in RDF and query them with SPARQL) must adapt and be redesigned to facilitate horisonal and vertical scaling.&lt;/p&gt;
&lt;p&gt;So far, the scale-up seems to be solved with the large triple-stores
&lt;a href=&#34;#bibliography&#34;&gt;[1]&lt;/a&gt; that can handle big data volumes by adding more resources. E.g., propiertary triple-stores like the Spatial and Graph features in Oracle Database&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, the AnzoGraph DB&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; and the AllegroGraph&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; that can deal more than ~1T (10&lt;sup&gt;12&lt;/sup&gt;) triples or open-source triple stores like the Virtuoso Open Source Edition&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; (~58.58B = ~58.58x10&lt;sup&gt;9&lt;/sup&gt;), the Blazegraph&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; (~12.7B)  and the Jena TDB&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; (~1.7B). As we can see, in terms of dealing with big data volumes, open-source solutions are behind of those propiertary or licensing alternatives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Are those numbers big enough?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;According to Orgacle&amp;rsquo;s white paper
&lt;a href=&#34;#bibliography&#34;&gt;[2]&lt;/a&gt;, 1T triples can represent:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;1000 tweets for every one of the 1B Twitter users.&lt;/li&gt;
&lt;li&gt;770 facts about every one of the 1.3B Facebook users.&lt;/li&gt;
&lt;li&gt;400 metabolic readings for eachof the 2.5 Billion heart beats over an average human life time.&lt;/li&gt;
&lt;li&gt;12 facts about every one of the 86B neurons in the human brain.&lt;/li&gt;
&lt;li&gt;5 facts about every one of the 200B stars in the Milky Way Galaxy.&lt;/li&gt;
&lt;li&gt;7 facts about every one of the 150B galaxies in the universe.&lt;/li&gt;
&lt;li&gt;10 facts about each of the 107B people who ever lived.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;On the other hand, when talking about scale-out solutions for large triple-stores we find that scale-out solutions are offered by most of the propiertary platforms or only in licensing versions like Virtuoso Enterprise Edition, with the exception of Blazegraph which is the only open source platform that offers scale-out.&lt;/p&gt;
&lt;p&gt;To know more about Blazegraph scale-out possibilities, I recommend you to read the following post:







  
    










  


&lt;div class=&#34;view-list-item&#34;&gt;
  &lt;i class=&#34;far fa-newspaper pub-icon&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
  &lt;a href=&#34;https://ga11u.github.io/post/blazegraph-scale-out/&#34; &gt;Scaling-out Blazegraph, is it possible?&lt;/a&gt;

  

  

  

&lt;/div&gt;

  

&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So what? What can we do if we need to scale-out triple-stores and we want to use and support open-source projects?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If we don&amp;rsquo;t want to work with a propertary or licensing tripe-stores but still needing a scale-out configuration, then we have two options: (1) using some open source triple-store on top of a highly scalable database like Apache HBase&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; or (2) we can use a graph database in combination with Gremlin. Both options have their pros and cons. Using a triple-store in combination with a highly scalable DB provides with the benefits of both platforms but the system maintenance and complexity is considerably increased. Whereas, while most of the graph databases do not support RDF, SPARQL, do not have reasoning or infering services and SPARQL quieres have to be translated to other query languages like Gremlin&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt; (although not all SPARQL queries can be transformed to Gremlin and Gremlin only supports SPARQL 1.0 and not 1.1), there is only one system to configure and maintain.&lt;/p&gt;
&lt;p&gt;Examples of such soultions are: the Jena+HBase triple-store which combines Apache Jena with Apache HBase to provide a scalable triple-store using RDF and SPARQL, Titan&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt; and JanusGraph&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt; graph databases that run on top of Apache HBase and Cassandra&lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt; and suport Gremlin, or Neo4j&lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt; and ArangoDB&lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt; graph databases that also suport Gremlin.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2 id=&#34;bibliography&#34;&gt;Bibliography&lt;/h2&gt;
&lt;p&gt;[1] W3C. &lt;em&gt;LargeTripleStores&lt;/em&gt;: &lt;a href=&#34;https://www.w3.org/wiki/LargeTripleStores&#34;&gt;https://www.w3.org/wiki/LargeTripleStores&lt;/a&gt; (last accessed 26/08/2020)&lt;/p&gt;
&lt;p&gt;[2] Oracle. &lt;em&gt;Oracle Spatial Graph RDF graph 1 trillion Benchmark&lt;/em&gt; &lt;a href=&#34;https://download.oracle.com/otndocs/tech/semantic_web/pdf/OracleSpatialGraph_RDFgraph_1_trillion_Benchmark.pdf&#34;&gt;https://download.oracle.com/otndocs/tech/semantic_web/pdf/OracleSpatialGraph_RDFgraph_1_trillion_Benchmark.pdf&lt;/a&gt; (last accessed 26/08/2020)&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.oracle.com/database/technologies/spatialandgraph.html&#34;&gt;https://www.oracle.com/database/technologies/spatialandgraph.html&lt;/a&gt; &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cambridgesemantics.com/anzograph&#34;&gt;https://www.cambridgesemantics.com/anzograph&lt;/a&gt; &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://allegrograph.com&#34;&gt;https://allegrograph.com&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://virtuoso.openlinksw.com&#34;&gt;https://virtuoso.openlinksw.com&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://blazegraph.com&#34;&gt;https://blazegraph.com&lt;/a&gt; &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://jena.apache.org&#34;&gt;https://jena.apache.org&lt;/a&gt; &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://hbase.apache.org&#34;&gt;https://hbase.apache.org&lt;/a&gt; &lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://tinkerpop.apache.org&#34;&gt;https://tinkerpop.apache.org&lt;/a&gt; &lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://titan.thinkaurelius.com&#34;&gt;http://titan.thinkaurelius.com&lt;/a&gt; &lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://janusgraph.org&#34;&gt;https://janusgraph.org&lt;/a&gt; &lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://cassandra.apache.org&#34;&gt;https://cassandra.apache.org&lt;/a&gt; &lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://neo4j.com&#34;&gt;https://neo4j.com&lt;/a&gt; &lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.arangodb.com&#34;&gt;https://www.arangodb.com&lt;/a&gt; &lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>
