[{"authors":["admin"],"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ga11u.github.io/author/marc-gallofre/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/marc-gallofre/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Marc GallofrÃ©","type":"authors"},{"authors":["Marc GallofrÃ©"],"categories":["News Angler","Blazegraph","Software Architecture","Semantic technologies"],"content":"Blagraph was presented as a high performance scale-out triple-store for big data in it initials and it can support up to ~12.7B triples in a single machine. At the beginning (from the 2.0.0 release), the scale-out was moved to a Enterprise fueture under licence supriptions, as we can see from the following information about High Availability (HA) and Scale-out features in the Blazegraph Blog (https://blog.blazegraph.com/) :\n Enterprise Features (HA and Scale-out)\nStarting in release 2.0.0, the Scale-out and HA capabilities are moved to Enterprise features. These are available to uses with support and/or license subscription. If you are an existing GPLv2 user of these features, we have some easy ways to migrate. Contact us for more information. Weâ€™d like to make it as easy as possible.\n Later, the support for High Availability was droped out from the project, due to the lack of open source community, as it is corroborated by Bryan Thompson (@thompsonbry), the Chief Scientist and founder of SYSTAP and one of the contributors of Blazegraph, in the issue #116 at Blazegraph/database GitHub (https://github.com/blazegraph/database/issues/116):\n The HA configuration is not functional in more recent releases. Systap halted development of the Blazegraph HA feature several years ago (long before we came to Amazon). Full HA is a complex thing to develop and maintain with master failure, testing of the various failover configurations, longevity testing, targeted failure mode tests, etc. We self-funded quite a bit, but we did not get the engagement from the open source community to make it worth while to continue HA as an open source feature.\nYou can always do the poor man\u0026rsquo;s HA, put the updates onto a durable queue, and then apply writes to each server in parallel. You would need to handle master failover of course. Or you can capture the IChangeLog from one server and replicate the post-facto changes (in terms of statements added and removed) to the other servers, again using a durable queue to capture the post-commit change set. To do the latter, you would also need to report additions to the dictionary indices (which is not currently done, but which would not be that difficult to add in the LexiconRelation and an apply loop interface for the replicas to apply the deltas on their local indices). I think this might \u0026ldquo;just work\u0026rdquo;. The local journal tracks the transactions in flight and manages the recycling of deleted records once no transaction can read on those records. So transactional access to data should \u0026ldquo;work\u0026rdquo; on the replicas without doing anything else. Again, you would need to handle master failover, etc.\nThanks, Bryan\n Currently, since Blazegraph was taken over by Amazon (Neptune AWS), the project does not seem to be activly maintained. However, it is possible to scale-out Blazegraph and configure with HA clusters.\nTo set up a Clustered or HA version of Blazegraph the first requirment is to set up a shared disk volume which will be accessed by all nodes. Thus, contrary to other well-known big data soulutions like Apache Cassandra, all nodes are accessing to the same data instances and not to their own copies/versions. Zookeeper manages the services running on each node and the access to the knowledge graph is rotated along the nodes.\nYet, due to the lack of documentation and support for clustered and HA Blazegraph deployment, the scale-out option is only for those fearless adventurers who wants to try out a clustered and HA version of Blazegraph. A guide about how to deploy the clustered configuration can be found here https://github.com/blazegraph/database/wiki/ClusterGuide with the following advice: We recommend that you ask for help when attempting your first cluster install!; the HA configuration is explained here: https://github.com/blazegraph/database/wiki/HAJournalServer#Basic_Deployment; and a example with Wikidata deployment of Blazegraph can be found here: https://wikitech.wikimedia.org/wiki/Nova_Resource:Wikidata-query/Documentation (the author of this post doesn\u0026rsquo;t take responsabilities for your failed attempts or disasters \u0026ndash; if you success, I will like to hear and lear how you have manage it ðŸ˜„ )\nStill, the stand-alone version Blazegraph is a really interesting option for working with open source triple-store which can manage big data volumes.\n","date":1598430388,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598430388,"objectID":"eaa65dab4c2041c7ff280e3a9e363740","permalink":"https://ga11u.github.io/post/blazegraph-scale/","publishdate":"2020-08-26T10:26:28+02:00","relpermalink":"/post/blazegraph-scale/","section":"post","summary":"Blagraph was presented as a high performance scale-out triple-store for big data in it initials and it can support up to ~12.7B triples in a single machine. At the beginning (from the 2.","tags":["News Angler","Blazegraph","Software Architecture","Semantic technologies"],"title":"Scaling-out Blazegraph, is it possible?","type":"post"},{"authors":["Marc GallofrÃ©"],"categories":["News Angler","Triple Store","Software Architecture","Semantic technologies"],"content":"Semantic technologies are really interesting from a Big Data prespective. Yet, these technologies together with semantic web resources enhance Knowledge Graphs by providing reacher means for representing and defining facts, concepts, properties, relations and logic-rules, while facilitating knowledge graph understanding, integration and manipulation by using ontologies, standard vocabularies and linking its concepts to Linked Open Data (LOD) resources such as Wikidata, Schema.org or DBPedia. Nevertheless, Big Data cames with its known challanges like the need for systems that are able to scale-up and -out (vertical and horisontal scaling). Thus, semantic technologies and more precicely triple-stores which support RDF and SPARQL following the W3C and semantic web standards (i.e., the databases designed for storing knowledge graphs represented with triples in RDF and query them with SPARQL) must adapt and be redesigned to facilitate horisonal and vertical scaling.\nSo far, the scale-up seems to be solved with the large triple-stores1 that can handle big data volumes by adding more resources. E.g., propiertary triple-stores like the Spatial and Graph features in Oracle Database2, the AnzoGraph DB3 and the AllegroGraph4 that can deal more than ~1T (1012) triples or open-source triple stores like the Virtuoso Open Source Edition5 (~58.58B = ~58.58x109), the Blazegraph6 (~12.7B) and the Jena TDB7 (~1.7B). As we can see, in terms of dealing with big data volumes, open-source solutions are behind of those propiertary or licensing alternatives.\nAre those numbers big enough? According to Orgacle\u0026rsquo;s white paper8, 1T triples can represent:\n  1000 tweets for every one of the 1B Twitter users. 770 facts about every one of the 1.3B Facebook users. 400 metabolic readings for eachof the 2.5 Billion heart beats over an average human life time. 12 facts about every one of the 86B neurons in the human brain. 5 facts about every one of the 200B stars in the Milky Way Galaxy. 7 facts about every one of the 150B galaxies in the universe. 10 facts about each of the 107B people who ever lived.   On the other hand, when talking about scale-out solutions for large triple-stores we find that scale-out solutions are offered by most of the propiertary platforms or only in licensing versions like Virtuoso Enterprise Edition, with the exception of Blazegraph which is the only open source platform that offers scale-out.\nTo know more about Blazegraph scale-out possibilities, I recommend you to read the following post: \rScaling-out Blazegraph, is it possible?\r\rSo what? What can we do if we need to scale-out triple-stores and we want to use and support open-source projects?\nIf we don\u0026rsquo;t want to work with a propertary or licensing tripe-stores but still needing a scale-out configuration, then we have two options: (1) using some open source triple-store on top of a highly scalable database like Apache HBase9 or (2) we can use a graph database in combination with Gremlin. Both options have their pros and cons. Using a triple-store in combination with a highly scalable DB provides with the benefits of both platforms but the system maintenance and complexity is considerably increased. Whereas, while most of the graph databases do not support RDF, SPARQL, do not have reasoning or infering services and SPARQL quieres have to be translated to other query languages like Gremlin10 (although not all SPARQL queries can be transformed to Gremlin and Gremlin only supports SPARQL 1.0 and not 1.1), there is only one system to configure and maintain.\nExamples of such soultions are: the Jena+HBase triple-store which combines Apache Jena with Apache HBase to provide a scalable triple-store using RDF and SPARQL, Titan11 and JanusGraph12 graph databases that run on top of Apache HBase and Cassandra13 and suport Gremlin, or Neo4j14 and ArangoDB15 graph databases that also suport Gremlin.   https://www.w3.org/wiki/LargeTripleStores \u0026#x21a9;\u0026#xfe0e;\n https://www.oracle.com/database/technologies/spatialandgraph.html \u0026#x21a9;\u0026#xfe0e;\n https://www.cambridgesemantics.com/anzograph \u0026#x21a9;\u0026#xfe0e;\n https://allegrograph.com \u0026#x21a9;\u0026#xfe0e;\n https://virtuoso.openlinksw.com \u0026#x21a9;\u0026#xfe0e;\n https://blazegraph.com \u0026#x21a9;\u0026#xfe0e;\n https://jena.apache.org \u0026#x21a9;\u0026#xfe0e;\n https://download.oracle.com/otndocs/tech/semantic_web/pdf/OracleSpatialGraph_RDFgraph_1_trillion_Benchmark.pdf \u0026#x21a9;\u0026#xfe0e;\n https://hbase.apache.org \u0026#x21a9;\u0026#xfe0e;\n https://tinkerpop.apache.org \u0026#x21a9;\u0026#xfe0e;\n http://titan.thinkaurelius.com \u0026#x21a9;\u0026#xfe0e;\n https://janusgraph.org \u0026#x21a9;\u0026#xfe0e;\n https://cassandra.apache.org \u0026#x21a9;\u0026#xfe0e;\n https://neo4j.com \u0026#x21a9;\u0026#xfe0e;\n https://www.arangodb.com \u0026#x21a9;\u0026#xfe0e;\n   ","date":1597999945,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597999945,"objectID":"6f650ee55dbb0770817aeffeebdaee8a","permalink":"https://ga11u.github.io/post/triplestore_scale_out/","publishdate":"2020-08-21T10:52:25+02:00","relpermalink":"/post/triplestore_scale_out/","section":"post","summary":"Semantic technologies are really interesting from a Big Data prespective. Yet, these technologies together with semantic web resources enhance Knowledge Graphs by providing reacher means for representing and defining facts, concepts, properties, relations and logic-rules, while facilitating knowledge graph understanding, integration and manipulation by using ontologies, standard vocabularies and linking its concepts to Linked Open Data (LOD) resources such as Wikidata, Schema.","tags":["News Angler","Triple Store","Software Architecture","Semantic technologies"],"title":"Is It Possible to Sale-out Open Source Triple-Stores?","type":"post"}]